
https://pytorch.org/TensorRT/tutorials/serving_torch_tensorrt_with_triton.html


docker run --gpus '"device=0"' --rm -p 8000:8000 -p 8001:8001 -p 8002:8002 --net=host \
  -v /home/dudaji/shhong/model_repository:/models \
  nvcr.io/nvidia/tritonserver:22.04-py3 tritonserver --model-repository=/models


docker run -it --gpus 1 --net=host -v ${PWD}/:/scratch_space ai-chip-client
cd /scratch_space
